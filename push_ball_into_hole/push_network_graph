digraph {
	graph [size="33.3,33.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	125674387559488 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	125674387621056 [label=AddBackward0]
	125674387621344 -> 125674387621056
	125674387621344 [label=AddmmBackward0]
	125674387621008 -> 125674387621344
	125674387557648 [label="policy_net.6.bias
 (4)" fillcolor=lightblue]
	125674387557648 -> 125674387621008
	125674387621008 [label=AccumulateGrad]
	125674387621200 -> 125674387621344
	125674387621200 [label=ReluBackward0]
	125674387621440 -> 125674387621200
	125674387621440 [label=NativeLayerNormBackward0]
	125674387621632 -> 125674387621440
	125674387621632 [label=AddmmBackward0]
	125674387621824 -> 125674387621632
	125674387557328 [label="policy_net.3.bias
 (256)" fillcolor=lightblue]
	125674387557328 -> 125674387621824
	125674387621824 [label=AccumulateGrad]
	125674387621776 -> 125674387621632
	125674387621776 [label=ReluBackward0]
	125674387621920 -> 125674387621776
	125674387621920 [label=NativeLayerNormBackward0]
	125674387622112 -> 125674387621920
	125674387622112 [label=AddmmBackward0]
	125674387622304 -> 125674387622112
	125674387557008 [label="policy_net.0.bias
 (256)" fillcolor=lightblue]
	125674387557008 -> 125674387622304
	125674387622304 [label=AccumulateGrad]
	125674387622256 -> 125674387622112
	125674387622256 [label=CatBackward0]
	125674387622400 -> 125674387622256
	125674387622400 [label=ReluBackward0]
	125674387622640 -> 125674387622400
	125674387622640 [label=NativeLayerNormBackward0]
	125674387622736 -> 125674387622640
	125674387622736 [label=AddmmBackward0]
	125674387622928 -> 125674387622736
	125677961125600 [label="obs_net.3.bias
 (128)" fillcolor=lightblue]
	125677961125600 -> 125674387622928
	125674387622928 [label=AccumulateGrad]
	125674387622880 -> 125674387622736
	125674387622880 [label=ReluBackward0]
	125674387623024 -> 125674387622880
	125674387623024 [label=NativeLayerNormBackward0]
	125674387623216 -> 125674387623024
	125674387623216 [label=AddmmBackward0]
	125674387623408 -> 125674387623216
	125674483973504 [label="obs_net.0.bias
 (256)" fillcolor=lightblue]
	125674483973504 -> 125674387623408
	125674387623408 [label=AccumulateGrad]
	125674387623360 -> 125674387623216
	125674387623360 [label=TBackward0]
	125674387623456 -> 125674387623360
	125674473139840 [label="obs_net.0.weight
 (256, 24)" fillcolor=lightblue]
	125674473139840 -> 125674387623456
	125674387623456 [label=AccumulateGrad]
	125674387623168 -> 125674387623024
	125674673139648 [label="obs_net.1.weight
 (256)" fillcolor=lightblue]
	125674673139648 -> 125674387623168
	125674387623168 [label=AccumulateGrad]
	125674387623120 -> 125674387623024
	125677961126480 [label="obs_net.1.bias
 (256)" fillcolor=lightblue]
	125677961126480 -> 125674387623120
	125674387623120 [label=AccumulateGrad]
	125674387622832 -> 125674387622736
	125674387622832 [label=TBackward0]
	125674387623312 -> 125674387622832
	125674673139728 [label="obs_net.3.weight
 (128, 256)" fillcolor=lightblue]
	125674673139728 -> 125674387623312
	125674387623312 [label=AccumulateGrad]
	125674387622688 -> 125674387622640
	125677961126560 [label="obs_net.4.weight
 (128)" fillcolor=lightblue]
	125677961126560 -> 125674387622688
	125674387622688 [label=AccumulateGrad]
	125674387622544 -> 125674387622640
	125674473308784 [label="obs_net.4.bias
 (128)" fillcolor=lightblue]
	125674473308784 -> 125674387622544
	125674387622544 [label=AccumulateGrad]
	125674387622448 -> 125674387622256
	125674387622448 [label=ReluBackward0]
	125674387622976 -> 125674387622448
	125674387622976 [label=NativeLayerNormBackward0]
	125674387623648 -> 125674387622976
	125674387623648 [label=AddmmBackward0]
	125674387623552 -> 125674387623648
	125674387119840 [label="goal_net.3.bias
 (128)" fillcolor=lightblue]
	125674387119840 -> 125674387623552
	125674387623552 [label=AccumulateGrad]
	125674387623600 -> 125674387623648
	125674387623600 [label=ReluBackward0]
	125674387623744 -> 125674387623600
	125674387623744 [label=NativeLayerNormBackward0]
	125674387623936 -> 125674387623744
	125674387623936 [label=AddmmBackward0]
	125674387624128 -> 125674387623936
	125674483966704 [label="goal_net.0.bias
 (256)" fillcolor=lightblue]
	125674483966704 -> 125674387624128
	125674387624128 [label=AccumulateGrad]
	125674387624080 -> 125674387623936
	125674387624080 [label=TBackward0]
	125674387624176 -> 125674387624080
	125674473136640 [label="goal_net.0.weight
 (256, 6)" fillcolor=lightblue]
	125674473136640 -> 125674387624176
	125674387624176 [label=AccumulateGrad]
	125674387623888 -> 125674387623744
	125677974037232 [label="goal_net.1.weight
 (256)" fillcolor=lightblue]
	125677974037232 -> 125674387623888
	125674387623888 [label=AccumulateGrad]
	125674387623840 -> 125674387623744
	125674725185296 [label="goal_net.1.bias
 (256)" fillcolor=lightblue]
	125674725185296 -> 125674387623840
	125674387623840 [label=AccumulateGrad]
	125674387623072 -> 125674387623648
	125674387623072 [label=TBackward0]
	125674387624032 -> 125674387623072
	125674714736064 [label="goal_net.3.weight
 (128, 256)" fillcolor=lightblue]
	125674714736064 -> 125674387624032
	125674387624032 [label=AccumulateGrad]
	125674387623264 -> 125674387622976
	125674387556848 [label="goal_net.4.weight
 (128)" fillcolor=lightblue]
	125674387556848 -> 125674387623264
	125674387623264 [label=AccumulateGrad]
	125674387622592 -> 125674387622976
	125674387556928 [label="goal_net.4.bias
 (128)" fillcolor=lightblue]
	125674387556928 -> 125674387622592
	125674387622592 [label=AccumulateGrad]
	125674387622208 -> 125674387622112
	125674387622208 [label=TBackward0]
	125674387623504 -> 125674387622208
	125674473143600 [label="policy_net.0.weight
 (256, 256)" fillcolor=lightblue]
	125674473143600 -> 125674387623504
	125674387623504 [label=AccumulateGrad]
	125674387622064 -> 125674387621920
	125674387557088 [label="policy_net.1.weight
 (256)" fillcolor=lightblue]
	125674387557088 -> 125674387622064
	125674387622064 [label=AccumulateGrad]
	125674387622016 -> 125674387621920
	125674387557168 [label="policy_net.1.bias
 (256)" fillcolor=lightblue]
	125674387557168 -> 125674387622016
	125674387622016 [label=AccumulateGrad]
	125674387621728 -> 125674387621632
	125674387621728 [label=TBackward0]
	125674387622352 -> 125674387621728
	125674387557248 [label="policy_net.3.weight
 (256, 256)" fillcolor=lightblue]
	125674387557248 -> 125674387622352
	125674387622352 [label=AccumulateGrad]
	125674387621584 -> 125674387621440
	125674387557408 [label="policy_net.4.weight
 (256)" fillcolor=lightblue]
	125674387557408 -> 125674387621584
	125674387621584 [label=AccumulateGrad]
	125674387621536 -> 125674387621440
	125674387557488 [label="policy_net.4.bias
 (256)" fillcolor=lightblue]
	125674387557488 -> 125674387621536
	125674387621536 [label=AccumulateGrad]
	125674387621392 -> 125674387621344
	125674387621392 [label=TBackward0]
	125674387621872 -> 125674387621392
	125674387557568 [label="policy_net.6.weight
 (4, 256)" fillcolor=lightblue]
	125674387557568 -> 125674387621872
	125674387621872 [label=AccumulateGrad]
	125674387621248 -> 125674387621056
	125674387621248 [label=AddmmBackward0]
	125674387623984 -> 125674387621248
	125674387558448 [label="value_net.6.bias
 (1)" fillcolor=lightblue]
	125674387558448 -> 125674387623984
	125674387623984 [label=AccumulateGrad]
	125674387621680 -> 125674387621248
	125674387621680 [label=ReluBackward0]
	125674387621488 -> 125674387621680
	125674387621488 [label=NativeLayerNormBackward0]
	125674387622496 -> 125674387621488
	125674387622496 [label=AddmmBackward0]
	125674387624320 -> 125674387622496
	125674387558128 [label="value_net.3.bias
 (256)" fillcolor=lightblue]
	125674387558128 -> 125674387624320
	125674387624320 [label=AccumulateGrad]
	125674387623792 -> 125674387622496
	125674387623792 [label=ReluBackward0]
	125674387624416 -> 125674387623792
	125674387624416 [label=NativeLayerNormBackward0]
	125674387624608 -> 125674387624416
	125674387624608 [label=AddmmBackward0]
	125674387624800 -> 125674387624608
	125674387557808 [label="value_net.0.bias
 (256)" fillcolor=lightblue]
	125674387557808 -> 125674387624800
	125674387624800 [label=AccumulateGrad]
	125674387622256 -> 125674387624608
	125674387624752 -> 125674387624608
	125674387624752 [label=TBackward0]
	125674387624848 -> 125674387624752
	125674387557728 [label="value_net.0.weight
 (256, 256)" fillcolor=lightblue]
	125674387557728 -> 125674387624848
	125674387624848 [label=AccumulateGrad]
	125674387624560 -> 125674387624416
	125674387557888 [label="value_net.1.weight
 (256)" fillcolor=lightblue]
	125674387557888 -> 125674387624560
	125674387624560 [label=AccumulateGrad]
	125674387624512 -> 125674387624416
	125674387557968 [label="value_net.1.bias
 (256)" fillcolor=lightblue]
	125674387557968 -> 125674387624512
	125674387624512 [label=AccumulateGrad]
	125674387624224 -> 125674387622496
	125674387624224 [label=TBackward0]
	125674387624704 -> 125674387624224
	125674387558048 [label="value_net.3.weight
 (256, 256)" fillcolor=lightblue]
	125674387558048 -> 125674387624704
	125674387624704 [label=AccumulateGrad]
	125674387623696 -> 125674387621488
	125674387558208 [label="value_net.4.weight
 (256)" fillcolor=lightblue]
	125674387558208 -> 125674387623696
	125674387623696 [label=AccumulateGrad]
	125674387621968 -> 125674387621488
	125674387558288 [label="value_net.4.bias
 (256)" fillcolor=lightblue]
	125674387558288 -> 125674387621968
	125674387621968 [label=AccumulateGrad]
	125674387621152 -> 125674387621248
	125674387621152 [label=TBackward0]
	125674387624272 -> 125674387621152
	125674387558368 [label="value_net.6.weight
 (1, 256)" fillcolor=lightblue]
	125674387558368 -> 125674387624272
	125674387624272 [label=AccumulateGrad]
	125674387621056 -> 125674387559488
}
